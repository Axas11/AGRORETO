# app/services/data_aggregator.py
import json
import logging
import threading
import time
from collections import defaultdict
from datetime import datetime
from typing import Dict, List

from sqlmodel import Session

from app.models import Alert, Sensor, SensorData
from app.utils import engine

logger = logging.getLogger(__name__)


class SensorDataAggregator:
    """
    Agregador que acumula lecturas de sensores cada 5 segundos
    y guarda la media aritm√©tica cada 5 minutos
    """
    
    def __init__(self, interval_minutes: int = 5):
        """
        Inicializa el agregador de datos de sensores.
        
        Args:
            interval_minutes: Intervalo en minutos para calcular y guardar la media (por defecto 5)
        """
        self.interval_seconds = interval_minutes * 60
        self.buffer: Dict[int, Dict[str, List[float]]] = defaultdict(lambda: defaultdict(list))
        self.raw_data_buffer: Dict[int, List[dict]] = defaultdict(list)
        self.lock = threading.Lock()
        self.running = False
        self.thread = None
        
        logger.info(f"üìä Agregador inicializado: media cada {interval_minutes} minutos")
    
    def add_reading(self, sensor_id: int, sensor_type: str, data: dict):
        """
        A√±ade una lectura de sensor al buffer en memoria para agregar posteriormente.
        Las lecturas se acumulan hasta que se ejecuta el c√°lculo de medias.
        Thread-safe mediante uso de lock.
        
        Args:
            sensor_id: ID del sensor en la base de datos
            sensor_type: Tipo de dato (temperatura, humedad_ambiente, iluminacion, etc.)
            data: Diccionario con todos los datos recibidos del sensor
        """
        with self.lock:
            # Obtener el valor espec√≠fico del sensor
            value = data.get(sensor_type, 0.0)
            
            # Guardar valor en buffer para calcular media
            self.buffer[sensor_id][sensor_type].append(float(value))
            
            # Guardar tambi√©n los datos completos (para el campo raw)
            self.raw_data_buffer[sensor_id].append(data)
            
            logger.debug(
                f"üì• Lectura a√±adida: Sensor {sensor_id} ({sensor_type}) = {value:.2f} "
                f"[{len(self.buffer[sensor_id][sensor_type])} lecturas acumuladas]"
            )
    
    def _calculate_and_save_averages(self):
        """
        Calcula la media aritm√©tica de todas las lecturas acumuladas en el buffer
        y las guarda en la base de datos como un √∫nico registro por sensor.
        
        Tambi√©n guarda metadatos (min, max, n√∫mero de muestras) en el campo 'raw'.
        Verifica umbrales despu√©s de guardar cada media.
        """
        with self.lock:
            if not self.buffer:
                logger.debug("üìä No hay lecturas para procesar")
                return
            
            # Copiar y limpiar buffers
            buffer_snapshot = dict(self.buffer)
            raw_data_snapshot = dict(self.raw_data_buffer)
            self.buffer.clear()
            self.raw_data_buffer.clear()
        
        # Procesar fuera del lock para no bloquear nuevas lecturas
        timestamp = datetime.now()
        
        try:
            with Session(engine) as session:
                for sensor_id, types_data in buffer_snapshot.items():
                    for sensor_type, values in types_data.items():
                        if not values:
                            continue
                        
                        # Calcular media aritm√©tica
                        avg_value = sum(values) / len(values)
                        
                        # Crear resumen para el campo raw
                        raw_summary = {
                            'aggregated': True,
                            'interval_minutes': self.interval_seconds // 60,
                            'samples_count': len(values),
                            'min': min(values),
                            'max': max(values),
                            'avg': avg_value,
                            'sensor_type': sensor_type,
                            'timestamp': timestamp.isoformat()
                        }
                        
                        # A√±adir datos adicionales del √∫ltimo mensaje completo si existen
                        if sensor_id in raw_data_snapshot and raw_data_snapshot[sensor_id]:
                            last_data = raw_data_snapshot[sensor_id][-1]
                            # Convertir datetime a string si existe
                            if 'timestamp' in last_data and isinstance(last_data['timestamp'], datetime):
                                last_data = last_data.copy()
                                last_data['timestamp'] = last_data['timestamp'].isoformat()
                            raw_summary['last_sample'] = last_data
                        
                        # Guardar en BD
                        reading = SensorData(
                            sensor_id=sensor_id,
                            timestamp=timestamp,
                            value=round(avg_value, 2),
                            raw=json.dumps(raw_summary)
                        )
                        
                        session.add(reading)
                        
                        logger.info(
                            f"üíæ Media guardada: Sensor {sensor_id} ({sensor_type}) = {avg_value:.2f} "
                            f"(de {len(values)} lecturas: min={min(values):.2f}, max={max(values):.2f})"
                        )
                        
                        # Verificar umbrales con la media
                        self._check_thresholds(session, sensor_id, sensor_type, avg_value)
                
                session.commit()
                logger.info(f"‚úÖ Guardado completado: {len(buffer_snapshot)} sensores procesados")
                
        except Exception as e:
            logger.exception(f"‚ùå Error guardando medias: {e}")
    
    def _check_thresholds(self, session: Session, sensor_id: int, sensor_type: str, value: float):
        """Verifica umbrales y crea alertas si es necesario"""
        try:
            sensor = session.get(Sensor, sensor_id)
            if not sensor:
                return
            
            alert_type = None
            alert_message = None
            
            if value < sensor.threshold_low:
                alert_type = "low"
                alert_message = (
                    f"‚ö†Ô∏è {sensor.id_code}: {sensor_type} bajo el m√≠nimo. "
                    f"Media: {value:.2f} {sensor.unit} (l√≠mite: {sensor.threshold_low})"
                )
            elif value > sensor.threshold_high:
                alert_type = "high"
                alert_message = (
                    f"‚ö†Ô∏è {sensor.id_code}: {sensor_type} sobre el m√°ximo. "
                    f"Media: {value:.2f} {sensor.unit} (l√≠mite: {sensor.threshold_high})"
                )
            
            if alert_type and alert_message:
                alert = Alert(
                    sensor_id=sensor_id,
                    timestamp=datetime.now(),
                    type=alert_type,
                    message=alert_message,
                    acknowledged=False
                )
                session.add(alert)
                session.commit()
                logger.warning(f"üö® ALERTA: {alert_message}")
                
        except Exception as e:
            logger.exception(f"‚ùå Error verificando umbrales: {e}")
    
    def _aggregation_loop(self):
        """
        Loop principal que ejecuta el c√°lculo y guardado de medias peri√≥dicamente.
        Se ejecuta en un thread separado cada interval_seconds.
        """
        logger.info(f"üîÑ Loop de agregaci√≥n iniciado (cada {self.interval_seconds}s)")
        
        while self.running:
            time.sleep(self.interval_seconds)
            
            if self.running:  # Verificar nuevamente despu√©s del sleep
                logger.info("‚è∞ Ejecutando agregaci√≥n de datos...")
                self._calculate_and_save_averages()
    
    def start(self):
        """
        Inicia el thread de agregaci√≥n en background.
        El thread ejecuta el c√°lculo de medias cada interval_minutes.
        """
        if self.running:
            logger.warning("‚ö†Ô∏è El agregador ya est√° en ejecuci√≥n")
            return
        
        self.running = True
        self.thread = threading.Thread(
            target=self._aggregation_loop,
            daemon=True,
            name="DataAggregator-Thread"
        )
        self.thread.start()
        logger.info("‚úÖ Agregador de datos iniciado en background")
    
    def stop(self):
        """
        Detiene el thread de agregaci√≥n de forma limpia.
        Guarda todos los datos pendientes en el buffer antes de terminar.
        """
        logger.info("üõë Deteniendo agregador de datos...")
        self.running = False
        
        if self.thread:
            self.thread.join(timeout=5)
        
        # Guardar datos pendientes
        logger.info("üíæ Guardando datos pendientes...")
        self._calculate_and_save_averages()
        logger.info("‚úÖ Agregador detenido correctamente")


# Instancia global del agregador (5 minutos por defecto)
data_aggregator = SensorDataAggregator(interval_minutes=5)
